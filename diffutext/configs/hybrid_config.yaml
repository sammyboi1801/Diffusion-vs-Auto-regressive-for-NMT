# Configuration for the Hybrid (DiffuText) Model

model_params:
  tokenizer_name: 'bert-base-uncased'
  # Paths to the pre-trained components
  diffusion_checkpoint: 'path/to/diffusion_model.pt'
  transformer_checkpoint: 'path/to/transformer_decoder.pt'

data:
  # Path for text data (for decoder training)
  text_path: 'path/to/your/dataset'
  # Path for latent data (for diffusion training, if done in this context)
  latent_path: 'path/to/your/latents'

training:
  # Define which part of the model to train: 'diffusion' or 'decoder'
  stage: 'decoder'
  batch_size: 32
  num_epochs: 15
  learning_rate: 0.0001

inference:
  max_length: 100

evaluation:
  batch_size: 32
